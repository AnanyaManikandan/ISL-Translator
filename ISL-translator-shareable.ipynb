{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "979b5574",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fddfd152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from matplotlib import  pyplot as plt \n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459143c8",
   "metadata": {},
   "source": [
    "# To Capture Keypoints using Holistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6279336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holistics Model\n",
    "mp_holistics = mp.solutions.holistic\n",
    "\n",
    "# To draw Keypoints\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea7c7356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  function to capture the keypoints from a video\n",
    "def media_pipe_detection(image, model):\n",
    "    #converting color from default opencv's BGR to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable =False\n",
    "    # Making Predictions\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable =True\n",
    "    #converting back to RGB to opencv's Default BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc10598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to draw landmarks\n",
    "def draw_landmarks(image, results):\n",
    "  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistics.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(80,22,76), thickness=2, circle_radius= 4),\n",
    "                              mp_drawing.DrawingSpec(color=(80,44,250), thickness=2, circle_radius= 2)\n",
    "                             )\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistics.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(80,117,66), thickness=2, circle_radius= 4),\n",
    "                              mp_drawing.DrawingSpec(color=(80,66,230), thickness=2, circle_radius= 2)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48a1b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to extract all the keypoints( left hand, right hand) which is in 2d arrray to 1d array.\n",
    "# In case if there is no key points then we will be returning array of zeros.\n",
    "def extract_keypoints(results):\n",
    "  \n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    \n",
    "    return np.concatenate([lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39523d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up folder for collections\n",
    "\n",
    "DATA_PATH = os.path.join(\"CUSTOM_ISL_DATA\")\n",
    "\n",
    "# actions we are detecting\n",
    "actions = np.array([\"hi\", \"thanks\", \"iloveyou\", \"sorry\"])\n",
    "\n",
    "# 50 videos to train\n",
    "no_sequences = 50\n",
    "\n",
    "# videos are going to be in frames of 30\n",
    "sequence_length = 30\n",
    "\n",
    "# start_folder =50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d1ff5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions: \n",
    "    for sequence in range(1, no_sequences+1):\n",
    "        try: \n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except:\n",
    "            pass\n",
    " \n",
    " # to make more than 50\n",
    "# for action in actions: \n",
    "#     for sequence in range(1+start_folder, no_sequences+start_folder+1):\n",
    "#         try: \n",
    "#             os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "#         except:\n",
    "#             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f3d3b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistics.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    \n",
    "    # Loop through actions\n",
    "    for action in actions:\n",
    "        # Loop through sequences aka videos\n",
    "        for sequence in range(1, no_sequences+1):\n",
    "            # Loop through video length aka sequence length\n",
    "            for frame_num in range(sequence_length):\n",
    "\n",
    "                # Read feed\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                # Make detections\n",
    "                image, results = media_pipe_detection(frame, holistic)\n",
    "#                 print(results)\n",
    "\n",
    "                # Draw landmarks\n",
    "                draw_landmarks(image, results)\n",
    "                \n",
    "                # Apply wait logic\n",
    "                if frame_num == 0: \n",
    "                    cv2.putText(image, 'STARTING COLLECTION', (120,200), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                    cv2.waitKey(2000)\n",
    "                else: \n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                \n",
    "                # Export keypoints\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "                np.save(npy_path, keypoints)\n",
    "\n",
    "                # Break\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86d2c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels and features\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bbb6a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5414aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in range(1, no_sequences+1):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "449d3b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing our data\n",
    "\n",
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2bfa771",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8673979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries to build model\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ab56749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,126)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62d6568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0338ad68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6/6 [==============================] - 3s 62ms/step - loss: 1.3746 - categorical_accuracy: 0.2667\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 1.2690 - categorical_accuracy: 0.5278\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.7917 - categorical_accuracy: 0.6222\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 2.1044 - categorical_accuracy: 0.7667\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 0s 52ms/step - loss: 0.8712 - categorical_accuracy: 0.5500\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 0s 51ms/step - loss: 0.7619 - categorical_accuracy: 0.6944\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.4714 - categorical_accuracy: 0.7833\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.3664 - categorical_accuracy: 0.8778\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.3702 - categorical_accuracy: 0.8611\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.2260 - categorical_accuracy: 0.9833\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0576 - categorical_accuracy: 0.9833\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.2126 - categorical_accuracy: 0.9333\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 1.4258 - categorical_accuracy: 0.9111\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1305 - categorical_accuracy: 0.9833\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0708 - categorical_accuracy: 0.9722\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 0.0212 - categorical_accuracy: 0.9833\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0138 - categorical_accuracy: 0.9944\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0799 - categorical_accuracy: 0.9833\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0258 - categorical_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0272 - categorical_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 0s 53ms/step - loss: 0.0075 - categorical_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 0s 55ms/step - loss: 0.0029 - categorical_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 0s 60ms/step - loss: 3.3821e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 0s 71ms/step - loss: 4.4104e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 0s 70ms/step - loss: 1.6267e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 8.3576e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 5.7920e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 5.0411e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 4.0130e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 3.6475e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 3.4058e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 3.0589e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 2.7980e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 2.6609e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 2.4695e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 2.2808e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 2.1861e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 2.0596e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 1.9523e-06 - categorical_accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.0571e-06 - categorical_accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m tb_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTensorBoard(log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs/\u001b[39m\u001b[38;5;124m\"\u001b[39m, histogram_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\keras\\engine\\training.py:1435\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1432\u001b[0m   val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m   1433\u001b[0m   epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[1;32m-> 1435\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1436\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m epoch_logs\n\u001b[0;32m   1437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\keras\\callbacks.py:416\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    414\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_logs(logs)\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m--> 416\u001b[0m   \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\keras\\callbacks.py:2506\u001b[0m, in \u001b[0;36mTensorBoard.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   2503\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_epoch_metrics(epoch, logs)\n\u001b[0;32m   2505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistogram_freq \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistogram_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2506\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings_freq \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2509\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_embeddings(epoch)\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\keras\\callbacks.py:2574\u001b[0m, in \u001b[0;36mTensorBoard._log_weights\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m   2572\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m weight \u001b[38;5;129;01min\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mweights:\n\u001b[0;32m   2573\u001b[0m   weight_name \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 2574\u001b[0m   \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2575\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_images:\n\u001b[0;32m   2576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_weight_as_image(weight, weight_name, epoch)\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorboard\\plugins\\histogram\\summary_v2.py:194\u001b[0m, in \u001b[0;36mhistogram\u001b[1;34m(name, data, step, buckets, description)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;129m@lazy_tensor_creator\u001b[39m\u001b[38;5;241m.\u001b[39mLazyTensorCreator\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_tensor\u001b[39m():\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _buckets(data, buckets)\n\u001b[1;32m--> 194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msummary_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:767\u001b[0m, in \u001b[0;36mwrite\u001b[1;34m(tag, tensor, step, metadata, name)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies([write_summary_op]):\n\u001b[0;32m    765\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m constant_op\u001b[38;5;241m.\u001b[39mconstant(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 767\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43msmart_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmart_cond\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshould_record_summaries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_nothing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msummary_cond\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    770\u001b[0m   ops\u001b[38;5;241m.\u001b[39madd_to_collection(ops\u001b[38;5;241m.\u001b[39mGraphKeys\u001b[38;5;241m.\u001b[39m_SUMMARY_COLLECTION, op)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py:53\u001b[0m, in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pred_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m pred_value:\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrue_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m false_fn()\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:755\u001b[0m, in \u001b[0;36mwrite.<locals>.record\u001b[1;34m()\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[38;5;66;03m# Note the identity to move the tensor to the CPU.\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 755\u001b[0m   summary_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m callable(tensor) \u001b[38;5;28;01melse\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(\n\u001b[0;32m    756\u001b[0m       tensor)\n\u001b[0;32m    757\u001b[0m   write_summary_op \u001b[38;5;241m=\u001b[39m gen_summary_ops\u001b[38;5;241m.\u001b[39mwrite_summary(\n\u001b[0;32m    758\u001b[0m       _summary_state\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39m_resource,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    759\u001b[0m       step,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    762\u001b[0m       serialized_metadata,\n\u001b[0;32m    763\u001b[0m       name\u001b[38;5;241m=\u001b[39mscope)\n\u001b[0;32m    764\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies([write_summary_op]):\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorboard\\util\\lazy_tensor_creator.py:66\u001b[0m, in \u001b[0;36mLazyTensorCreator.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor \u001b[38;5;241m=\u001b[39m _CALL_IN_PROGRESS_SENTINEL\n\u001b[1;32m---> 66\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorboard\\plugins\\histogram\\summary_v2.py:192\u001b[0m, in \u001b[0;36mhistogram.<locals>.lazy_tensor\u001b[1;34m()\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;129m@lazy_tensor_creator\u001b[39m\u001b[38;5;241m.\u001b[39mLazyTensorCreator\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_tensor\u001b[39m():\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_buckets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuckets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorboard\\plugins\\histogram\\summary_v2.py:291\u001b[0m, in \u001b[0;36m_buckets\u001b[1;34m(data, bucket_count)\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mtranspose(a\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mstack([edges, edges, bucket_counts]))\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcond(\n\u001b[0;32m    288\u001b[0m         has_single_value, when_single_value, when_multiple_values\n\u001b[0;32m    289\u001b[0m     )\n\u001b[1;32m--> 291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_empty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhen_empty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhen_nonempty\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:1452\u001b[0m, in \u001b[0;36mcond_for_tf_v2\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcond\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m   1382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcond_for_tf_v2\u001b[39m(pred, true_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, false_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1383\u001b[0m   \u001b[38;5;124;03m\"\"\"Return `true_fn()` if the predicate `pred` is true else `false_fn()`.\u001b[39;00m\n\u001b[0;32m   1384\u001b[0m \n\u001b[0;32m   1385\u001b[0m \u001b[38;5;124;03m  `true_fn` and `false_fn` both return lists of output tensors. `true_fn` and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1450\u001b[0m \n\u001b[0;32m   1451\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1452\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfalse_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:548\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    540\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    541\u001b[0m       logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    542\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    543\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    546\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[0;32m    547\u001b[0m           instructions)\n\u001b[1;32m--> 548\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:1261\u001b[0m, in \u001b[0;36mcond\u001b[1;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[0;32m   1258\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfalse_fn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be callable.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m-> 1261\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eager_cond_implementation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfalse_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;66;03m# Always enable control flow v2 if building a function, regardless of toggle.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m util\u001b[38;5;241m.\u001b[39mEnableControlFlowV2(ops\u001b[38;5;241m.\u001b[39mget_default_graph()):\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:1150\u001b[0m, in \u001b[0;36m_eager_cond_implementation\u001b[1;34m(pred, true_fn, false_fn, strict, name)\u001b[0m\n\u001b[0;32m   1148\u001b[0m   result \u001b[38;5;241m=\u001b[39m true_fn()\n\u001b[0;32m   1149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1150\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mfalse_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict:\n\u001b[0;32m   1152\u001b[0m   result \u001b[38;5;241m=\u001b[39m _UnpackIfSingleton(result)\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorboard\\plugins\\histogram\\summary_v2.py:287\u001b[0m, in \u001b[0;36m_buckets.<locals>.when_nonempty\u001b[1;34m()\u001b[0m\n\u001b[0;32m    281\u001b[0m     bucket_counts \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(\n\u001b[0;32m    282\u001b[0m         tf\u001b[38;5;241m.\u001b[39mconcat([zeroes[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], [data_size]], \u001b[38;5;241m0\u001b[39m)[:bucket_count],\n\u001b[0;32m    283\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[0;32m    284\u001b[0m     )\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mtranspose(a\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mstack([edges, edges, bucket_counts]))\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_single_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhen_single_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhen_multiple_values\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:1452\u001b[0m, in \u001b[0;36mcond_for_tf_v2\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcond\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m   1382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcond_for_tf_v2\u001b[39m(pred, true_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, false_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1383\u001b[0m   \u001b[38;5;124;03m\"\"\"Return `true_fn()` if the predicate `pred` is true else `false_fn()`.\u001b[39;00m\n\u001b[0;32m   1384\u001b[0m \n\u001b[0;32m   1385\u001b[0m \u001b[38;5;124;03m  `true_fn` and `false_fn` both return lists of output tensors. `true_fn` and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1450\u001b[0m \n\u001b[0;32m   1451\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1452\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfalse_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:548\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    540\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    541\u001b[0m       logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    542\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    543\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    546\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[0;32m    547\u001b[0m           instructions)\n\u001b[1;32m--> 548\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:1261\u001b[0m, in \u001b[0;36mcond\u001b[1;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[0;32m   1258\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfalse_fn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be callable.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m-> 1261\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eager_cond_implementation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfalse_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[38;5;66;03m# Always enable control flow v2 if building a function, regardless of toggle.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m util\u001b[38;5;241m.\u001b[39mEnableControlFlowV2(ops\u001b[38;5;241m.\u001b[39mget_default_graph()):\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:1150\u001b[0m, in \u001b[0;36m_eager_cond_implementation\u001b[1;34m(pred, true_fn, false_fn, strict, name)\u001b[0m\n\u001b[0;32m   1148\u001b[0m   result \u001b[38;5;241m=\u001b[39m true_fn()\n\u001b[0;32m   1149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1150\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mfalse_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict:\n\u001b[0;32m   1152\u001b[0m   result \u001b[38;5;241m=\u001b[39m _UnpackIfSingleton(result)\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorboard\\plugins\\histogram\\summary_v2.py:256\u001b[0m, in \u001b[0;36m_buckets.<locals>.when_nonempty.<locals>.when_multiple_values\u001b[1;34m()\u001b[0m\n\u001b[0;32m    252\u001b[0m clamped_indices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mminimum(bucket_indices, bucket_count \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# Use float64 instead of float32 to avoid accumulating floating point error\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;66;03m# later in tf.reduce_sum when summing more than 2^24 individual `1.0` values.\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;66;03m# See https://github.com/tensorflow/tensorflow/issues/51419 for details.\u001b[39;00m\n\u001b[1;32m--> 256\u001b[0m one_hots \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclamped_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbucket_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m bucket_counts \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(\n\u001b[0;32m    260\u001b[0m     tf\u001b[38;5;241m.\u001b[39mreduce_sum(input_tensor\u001b[38;5;241m=\u001b[39mone_hots, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    261\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[0;32m    262\u001b[0m )\n\u001b[0;32m    263\u001b[0m edges \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlinspace(min_, max_, bucket_count \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:4404\u001b[0m, in \u001b[0;36mone_hot\u001b[1;34m(indices, depth, on_value, off_value, axis, dtype, name)\u001b[0m\n\u001b[0;32m   4400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_dtype \u001b[38;5;241m!=\u001b[39m off_dtype:\n\u001b[0;32m   4401\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m of on_value does not match \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4402\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m of off_value\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(on_dtype, off_dtype))\n\u001b[1;32m-> 4404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moff_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4405\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ml_ds\\ML_PROJECTS\\INDIAN_SIGN_LANGUAGE_TRANSLATOR\\env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:6398\u001b[0m, in \u001b[0;36mone_hot\u001b[1;34m(indices, depth, on_value, off_value, axis, name)\u001b[0m\n\u001b[0;32m   6396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   6397\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 6398\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   6399\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOneHot\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moff_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maxis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6400\u001b[0m \u001b[43m      \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   6402\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/\", histogram_freq=1)\n",
    "model.fit(x_train, y_train, epochs=1000, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22d8290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2983f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reload tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f46d5f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 14928), started 2 days, 1:06:07 ago. (Use '!kill 14928' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cb41bf523ad73680\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cb41bf523ad73680\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to open tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "524ae105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 30, 64)            48896     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 30, 128)           98816     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 199,332\n",
      "Trainable params: 199,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "236be9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "760b9eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i in range(len(res)):\n",
    "    if actions[np.argmax(res[i])] == actions[np.argmax(y_test[i])]: correct+=1\n",
    "    total+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3edeb5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a74b45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9aa1c639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 569ms/step - loss: 3.6239e-06 - categorical_accuracy: 1.0000\n",
      "Accuracy: 100.00%\n",
      "Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test,y_test);\n",
    "print(\"Accuracy: {:.2f}%\".format(acc*100));\n",
    "print(\"Loss: {:.4f}\".format(loss));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b34ac811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Evaluate model using confusion matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "183320a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[16,  0],\n",
       "        [ 0,  4]],\n",
       "\n",
       "       [[15,  0],\n",
       "        [ 0,  5]],\n",
       "\n",
       "       [[12,  0],\n",
       "        [ 0,  8]],\n",
       "\n",
       "       [[17,  0],\n",
       "        [ 0,  3]]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypreds = model.predict(x_test)\n",
    "\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "ypreds = np.argmax(ypreds, axis=1).tolist()\n",
    "\n",
    "multilabel_confusion_matrix(ytrue, ypreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13ab36f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy score\n",
    "accuracy_score(ytrue, ypreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ff6e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.models.save_model(model,'Final_Model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63e839c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(18,18))\n",
    "# plt.imshow(cv2.cvtColor(prob_viz(res, actions, image, colors),cv2.COLOR_BGR2RGB ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89b25f5",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57df0a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://6d43754e-f4a0-4d02-98bf-34e667f1da30/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000022C66971580> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000022C65ABAFD0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000022C6E7C7520> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model, open(\"ISL_Prediction_Model.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71332965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
